\chapter{Implementation}
\label{chapter-6}

This chapter primarily discusses the steps and modifications that has been carried out to tune the software. The imitation 
is performed initially with upper body and then to lower body eventually testing the complex motions considering the NAO robot's 
structure. The results of the implementation will be discussed in the coming sections later in this chapter.


\section{Methodology}

The implementation began by testing the robot's kinematics already implemented in order to obtain relation between it's joints  and task spaces.
Once the suitable implementation has been validated, the captured human data is scaled down to the robot's size and it's desired parameters $\Omega$
are retrieved for HQP.

\begin{figure}[h!]
    \centering
    \includegraphics[scale=0.5]{images/flowchart-block-diagram.png}\hfill
    \caption{Block Diagram Representation of Imitation Program}\hfill
    \label{fig: block-diagram}
\end{figure}

Figure \ref{fig: block-diagram} represents the flow of data between individual blocks discussed in chapter \ref{chapter-3} and 
chapter \ref{chapter-4}. It is notable that two computers are used for this implementation to extract convenient results.

\section{Robot Model}

During the course of this research, both real robot and virtual models are used. The real robot used for validation is
a NAO v5 H25 Humanoid robot and the virtual model is a CopelliaSim model with approximately equivalent inertial modelling.
Like previous implementations on kinematic modelling \cite{louisepouble}, the hand operations (open/close) will be ignored therby
controlling 23 DoFs in total (vector $q$). Figure \ref{fig: nao-robot-joint} represents the arrangement of DoFs that will be used in this research.

\begin{equation*}
    q = \begin{bmatrix}
        q_1 && q_2 && ... & q_{23}
    \end{bmatrix}^T
\end{equation*}
\begin{figure}[h!]
    \centering
    \includegraphics[scale=0.55]{images/nao-robot-joint.png}\hfill
    \caption{NAO Robot's DoF Arrangement \cite{louisepouble}}\hfill
    \label{fig: nao-robot-joint}
\end{figure}

\subsection{Kinematic Modelling}

The robot's geometric model was calculated using the nominal approach with \textit{Modified Denavit-Hartenberg} (MDH) parameters. Since the 
robot is a tree structure, some links have more than one child links. In addition, it might be convenient to include 
frames in the model which are not necessarily defined according to the previous rules. Then, the kinematic model can be represented as,

\begin{equation}
    \label{eq: robot-dgm-1}
    \begin{bmatrix}
        \dot{x}_{lhand} \\ \dot{x}_{rhand} \\ \dot{x}_{xleg} 
    \end{bmatrix} = J \begin{bmatrix}
        \dot{q}_{lhand} \\ \dot{q}_{rhand} \\ \dot{q}_{xleg}
    \end{bmatrix}
\end{equation}

Equation \ref{eq: robot-dgm-1} can be simply represented as $\dot{X} = J\dot{q}$ in the next sections where $J$ is the robot Jacobian and $x_i$ is a $3 \times 1$ vector without
considering the end-effector oriendation. $xleg$ refers to $lleg$ and $rleg$ depending on the support phase of the robot. Considering both feet 
of the robot for kinematic modelling uses all the joints $q$, the robot will not be redundant and adding tasks will cause overconstraint. To avoid the situation, two seperate models
were created such that the above equation has a vector size of $(6 + 5 + 5) \times 1$ considering only three kinematic chains for the sake of redundancy. 
In other words, either left foot or right foot will always be in contact with the environment (\textit{i.e.} floor).
This work was implemented in MATLAB and was exported to a C++ library "Jacobian" (available in \cite{github}). 

\subsection{Support Phases}

Since the kinematic analysis is composed of two models for each single support (right foot and left foot), the computation is extended to a lighter version compared to the computation 
of 23 joints. The transition between single support (SS) and double support (DS) is tabulated in Table \ref{tab: support-phases} which introduces the constraints of using the kinematic models developed in the 
above section.


In table \ref{tab: support-phases}, FH refers to the feet height of NAO, LH refers to the lift height during single support of the respective legs. $X_{balance}$ refers to the optimal 
projection of CoM onto the horizontal plane during the imitation process. 

\begin{table}[h!]
    \label{tab: support-phases}
    \begin{tabular}{|l|c|c|c|c|c|}
        \hline
        Support & Pos. of abs. frame & $X$ & $X_{balance}$ & DS (constraint) & SS (constraint)\\
        \hline
        Right Foot & Right Foot  & $\begin{bmatrix}
            x_{lhand} \\ x_{rhand} \\ x_{lankle}
        \end{bmatrix}$ & $\begin{bmatrix}
            0 \\ 0
        \end{bmatrix}$ & $z_{lankle} = FH$ & $z_{lankle} = FH + LH$ \\
        \hline
        Both feet & Right Foot  & $\begin{bmatrix}
            x_{lhand} \\ x_{rhand} \\ x_{lankle} \\z_{lfoot} = 0 \\z_{ltoe} = 0
        \end{bmatrix}$ & $\begin{bmatrix}
            \frac{x_{lfoot}}{2} \\ \frac{y_{lfoot}}{2}
        \end{bmatrix}$ & - & - \\
        \hline
        Left Foot & Left Foot & $\begin{bmatrix}
            x_{lhand} \\ x_{rhand} \\ x_{rankle}
        \end{bmatrix}$ & $\begin{bmatrix}
            0 \\ 0
        \end{bmatrix}$ & $z_{rankle} = FH$ & $z_{rankle} = FH + LH$\\
        \hline
    \end{tabular}
    \caption{Transition between support phases}
\end{table}


\subsection{Masses and CoM}

The robot's dynamic parameters like masses and Centre of Masses can be obtained from the 
documentation directly \cite{aldebaran-masses}. The individual masses and CoM for each link 
is calculated and documented in the website. To calculate the single point mass and the projection of 
CoM onto xy plane is,

\begin{align}
    \label{eq: robot-mass-com}
    M &= \Sigma_{i = 1}^n m_i \\
    P_{CoM} &= \frac{1}{M}\Sigma_{i = 1}^n m_ic_i
\end{align}

where $m_i$ and $c_i$ represent the individual mass and CoM of link $i$ obtained from documentation respectively; n is the number of moving masses 
in the robot body. The jacobian of CoM can then be formulated with respect to the robot frame (frame located at right foot) is given by,

\begin{align}
    \label{eq: robot-mass-com-2}
    J_{CoM} &= \frac{\partial P_{CoM}}{\partial q} \quad \mathit{or} \\
    \dot{P}_{CoM} &= J_{CoM} \dot{q}
\end{align}

The size of $J_{CoM}$ is $2 \times 23$ (reflection of CoM onto 2D plane (x, y)). $P_{CoM}$ is a 2-dimensional vector since the projection on xy plane.

\section{Human Motion}

The sensor data acquired from Xsens suit is high-quality less-noise data with the ability to record wide range of motions.
The data acquired greatly differ in cartesian sizing compared to the size of the NAO robot. Usually in motion imitation, the robot 
must reach the same point in task space as the human actor, but due to greater difference in size, the task space is treated as relative instead of absolute. 
To achieve this criteria, a scaling function need to be implemented before
feeding the Xsens data to the robot control.

\subsection*{Scaling Function}

In a previous work \cite{scaling-human-nao}, the use of a scaling factor for each limb based on the ratio between the lengths of the kinematic chain of actor and 
imitator was proposed. This factor was then multiplied by the captured human data to obtain the desired positions for the robot. Since each limb 
was a simple serial chain, a proportional scaling factor could be applied satisfactorily.

However, in the present work, the balance is being taken into account and thus the robot has to be modelled as a whole, which gives rise to s 
tree-structure. In this case, keeping the direction of the captured human data means that the robot’s end-effectors will fall on the line which 
connects the tracked points to the origin on the right foot.

\begin{figure}[h!]
    \centering
    \includegraphics[scale=0.7]{images/proportional-scaling.png}\hfill
    \caption{Proportional scaling of human motion \cite{louisepouble}}\hfill
    \label{fig: proportional scaling}
\end{figure}

A new scaling method is proposed in \cite{sakka:hal-01054887} which takes into account not only the
lengths of each of the segments but also each of their directions. This way, the captured
human motion is scaled segment by segment to the lengths of the robot while keeping the 
direction of that segment. The iterative process starts from the right ankle and moves upwards towards each of the end-effectors.

In summary considering a link $l$, the scaling can be processed as,

\begin{equation}
    P_l^{robot} = \frac{P_l^{human} - P_a^{human}}{||P_l^{human} - P_a^{human}||}l_l^{robot} + P_a^{robot}
\end{equation}

~

where $P_a$ refers to the antecedent position to the link $l$. Since the robot doesn’t have a spine, the distances connecting shoulders and hips 
should remain constant. The shoulders cannot be scaled directly from the hips because of the different torso proportions between the human and the 
robot. It was chosen to scale a segment which goes from the point between the hips to the point between the shoulders, preserving symmetry. Also the 
position of absolute frame during single support is at right foot at any case. Considering the support changes into imitation, the absolute frame 
cannot stay at right frame and hence moved to the center of the feet. A threshold of 200 mm is set to avoid false positives due to jittering.

\section{Robot Control}

For the robot control part, the program is developed with the possiblity of extending as an application to the NAO community. The data received from 
Xsens is processed and sent to the robot control for motion imitation. 
A flowchart of the program is shown on Figure \ref{fig: flowchart-robot-control}.

\begin{figure}[h!]
    \centering
    \includegraphics[scale=0.4]{images/flowchart-robot-control.png}\hfill
    \caption{Flowchart Representation of Imitation Program}\hfill
    \label{fig: flowchart-robot-control}
\end{figure}

Each block of the flowchart is individually explained in Chapter \ref{chapter-3} and Chapter \ref{chapter-4}. However an summary of each block is provided
in subsections below.

\subsection*{Initial Pose}

The initial poses are the identity poses used when calibrating Xsens suit. In this work, only N-pose will be considered as the initial pose in both the case of calibration
and the experimentation. Once the experimentation starts, a delay of 5 seconds will let the xsens user to pose in N-pose followed by the imitation program.

\subsection*{Start Imitation}

Start Imitation allows the user to define the configurations for the imitation program. An additional section for letting the user to use recorded motion or real-time 
imitation can also be setup depending on the situation. If the imitation is online, the program will wait for the first message to be delivered by Xsens Analyze software.

\subsection*{Hardware}

The hardware interface lets the xsens and NAO services get started to check connectivity between services and joint data buffers. Once the data is acquired without
any interference the actual imitation is started.

\subsection*{Process data}

The acquired UDP message from Xsens needs to be processed to a readable numerical format for further actions. The NAOqi proxy lets collecting data from robot joint buffers and memory 
buffers. The real-time sensors and encoders can be acquired from ALProxy, ALMotion and ALMemory services.

\subsection*{Desired Task Vectors}

The desired task vectors are processed from human actor. The essential parameters like $X, \ddot{X}, P_{CoM, H}$ and $q_{H}$ are assigned to the temporary memory buffer and scaled to the size 
of the robot. The vectors and matrices are formatted to the required dimensions of HQP solver.

\subsection*{Current Task Vectors}

The current task vectors are derived from robot memory buffer. The memory buffer is handled using ALMemory proxy and ALPose proxy and are formatted to the vector and matrices.

\subsection*{HQP Solver}

The task vectors and constraints described in section \ref{sec: HQP-imitation} will be programmed in C++ using the library \textit{QPOases}. 

Several iterations might be needed for the IK to reach the final goal, even if the final goal has been scaled down. However, since this is a numerical approach, 
it is not assured that a solution will be found. In fact, after some iterations, if the hard constraints are not reachable or compatible, the pseudo-inverse won’t 
come to any useful results. Thus, a maximum number of iterations is set beforehand, so if the IK is taking too many iter- ations to be solved, the current goal can 
be abandoned and new human data should be taken. It was observed that good results are usually obtained with less than 6 iterations, so a safe limit was set at 
maxIterations = 20 \cite{louisepouble}.

\section{Results}

The 